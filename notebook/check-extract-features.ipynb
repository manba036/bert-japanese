{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴ベクトル抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■定数を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = '../config.ini'\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PRETRAINED_MODEL_PATH = '../model/bert-wiki-ja/model.ckpt-1400000'\n",
    "TOKENIZER_MODEL_PATH = '../model/bert-wiki-ja/wiki-ja'\n",
    "INPUT_TEXTFILE_PATH = './data/input.txt'\n",
    "OUTPUT_TEXTFILE_PATH = './data/output.txt'\n",
    "OUTPUT_JSONFILE_PATH = './data/output.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■モジュールを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import tarfile \n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import tempfile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src\")\n",
    "from utils import str_to_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../bert\")\n",
    "import modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■設定ファイルを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config.ini']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEURL = config['FINETUNING-DATA']['FILEURL']\n",
    "FILEPATH = config['FINETUNING-DATA']['FILEPATH']\n",
    "EXTRACTDIR = config['FINETUNING-DATA']['TEXTDIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.json')\n",
    "bert_config_file.write(json.dumps({k:str_to_value(v) for k,v in config['BERT-CONFIG'].items()}))\n",
    "bert_config_file.seek(0)\n",
    "bert_config_file_path = str(bert_config_file.name)\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MAX_SEQ_LENGTH'] = str(MAX_SEQ_LENGTH) \n",
    "os.environ['PRETRAINED_MODEL_PATH'] = PRETRAINED_MODEL_PATH\n",
    "os.environ['TOKENIZER_MODEL_PATH'] = TOKENIZER_MODEL_PATH\n",
    "os.environ['INPUT_TEXTFILE_PATH'] = INPUT_TEXTFILE_PATH\n",
    "os.environ['OUTPUT_TEXTFILE_PATH'] = OUTPUT_TEXTFILE_PATH\n",
    "os.environ['OUTPUT_JSONFILE_PATH'] = OUTPUT_JSONFILE_PATH\n",
    "os.environ['BERT_CONFIGFILE_PATH'] = bert_config_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■入力文書を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 'すべての人間は、生れながらにして自由であり、かつ、尊厳と権利とについて平等である。 ||| 人間は、理性と良心とを授けられており、互いに同胞の精神をもって行動しなければならない。' > ${INPUT_TEXTFILE_PATH}\n",
    "echo '「富士〜」で有名な動物園は？ ||| 「富士サファリパーク」です。' >> ${INPUT_TEXTFILE_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■特徴ベクトルを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a trained SentencePiece model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0816 16:24:15.282077 140167059183424 deprecation_wrapper.py:119] From ../src/extract_features.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W0816 16:24:15.483777 140167059183424 deprecation_wrapper.py:119] From /work/bert-japanese/src/tokenization_sentencepiece.py:115: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0816 16:24:19.974902 140167059183424 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0816 16:24:19.976667 140167059183424 deprecation_wrapper.py:119] From ../src/extract_features.py:292: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0816 16:24:19.976818 140167059183424 extract_features.py:292] *** Example ***\n",
      "I0816 16:24:19.976936 140167059183424 extract_features.py:293] unique_id: 0\n",
      "I0816 16:24:19.977139 140167059183424 extract_features.py:295] tokens: [CLS] \\u2581 \\u3059\\u3079\\u3066\\u306e \\u4eba\\u9593 \\u306f \\u3001 \\u751f \\u308c \\u306a\\u304c\\u3089 \\u306b\\u3057\\u3066 \\u81ea\\u7531 \\u3067\\u3042\\u308a \\u3001 \\u304b\\u3064 \\u3001 \\u5c0a \\u53b3 \\u3068 \\u6a29\\u5229 \\u3068 \\u306b\\u3064\\u3044\\u3066 \\u5e73\\u7b49 \\u3067\\u3042\\u308b \\u3002 [SEP] \\u2581 \\u4eba\\u9593 \\u306f \\u3001 \\u7406\\u6027 \\u3068 \\u826f \\u5fc3 \\u3068 \\u3092 \\u6388\\u3051 \\u3089\\u308c\\u3066\\u304a\\u308a \\u3001 \\u4e92\\u3044\\u306b \\u540c\\u80de \\u306e\\u7cbe\\u795e \\u3092\\u3082\\u3063\\u3066 \\u884c\\u52d5 \\u3057\\u306a\\u3051\\u308c\\u3070\\u306a\\u3089\\u306a\\u3044 \\u3002 [SEP]\n",
      "I0816 16:24:19.977326 140167059183424 extract_features.py:296] input_ids: 4 9 2145 858 11 7 196 964 527 2113 1325 75 7 1368 7 3201 3586 20 3334 20 257 10838 27 8 5 9 858 11 7 18570 20 856 509 20 18 15611 8880 7 6109 27717 14647 1806 1216 6807 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0816 16:24:19.977490 140167059183424 extract_features.py:297] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0816 16:24:19.977655 140167059183424 extract_features.py:299] input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0816 16:24:19.977991 140167059183424 extract_features.py:292] *** Example ***\n",
      "I0816 16:24:19.978088 140167059183424 extract_features.py:293] unique_id: 1\n",
      "I0816 16:24:19.978194 140167059183424 extract_features.py:295] tokens: [CLS] \\u2581\\u300c \\u5bcc\\u58eb \\u301c\\u300d \\u3067 \\u6709\\u540d\\u306a \\u52d5\\u7269\\u5712 \\u306f ? [SEP] \\u2581\\u300c \\u5bcc\\u58eb \\u30b5 \\u30d5\\u30a1 \\u30ea \\u30d1\\u30fc\\u30af \\u300d \\u3067\\u3059 \\u3002 [SEP]\n",
      "I0816 16:24:19.978358 140167059183424 extract_features.py:296] input_ids: 4 235 2915 10341 19 3225 12507 11 3017 5 235 2915 209 726 146 2361 21 2767 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0816 16:24:19.978518 140167059183424 extract_features.py:297] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0816 16:24:19.978675 140167059183424 extract_features.py:299] input_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "W0816 16:24:19.978942 140167059183424 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f7b049d4bf8>) includes params argument, but params are not passed to Estimator.\n",
      "W0816 16:24:19.980675 140167059183424 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp758akexs\n",
      "I0816 16:24:19.981723 140167059183424 estimator.py:209] Using config: {'_model_dir': '/tmp/tmp758akexs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7b01d71eb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
      "I0816 16:24:19.981991 140167059183424 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
      "W0816 16:24:19.982608 140167059183424 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
      "W0816 16:24:19.982813 140167059183424 deprecation_wrapper.py:119] From ../src/extract_features.py:407: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "I0816 16:24:19.983084 140167059183424 estimator.py:612] Could not find trained model in model_dir: /tmp/tmp758akexs, running initialization to predict.\n",
      "I0816 16:24:20.021204 140167059183424 estimator.py:1145] Calling model_fn.\n",
      "I0816 16:24:20.021500 140167059183424 tpu_estimator.py:2965] Running infer on CPU\n",
      "W0816 16:24:20.027370 140167059183424 deprecation_wrapper.py:119] From ../bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0816 16:24:20.029650 140167059183424 deprecation_wrapper.py:119] From ../bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0816 16:24:20.079526 140167059183424 deprecation_wrapper.py:119] From ../bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W0816 16:24:20.169587 140167059183424 deprecation.py:323] From ../bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0816 16:24:24.411541 140167059183424 deprecation_wrapper.py:119] From ../src/extract_features.py:180: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0816 16:24:24.420498 140167059183424 deprecation_wrapper.py:119] From ../src/extract_features.py:193: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "I0816 16:24:25.554825 140167059183424 extract_features.py:195] **** Trainable Variables ****\n",
      "I0816 16:24:25.555118 140167059183424 extract_features.py:201]   name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.555322 140167059183424 extract_features.py:201]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.555506 140167059183424 extract_features.py:201]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.555713 140167059183424 extract_features.py:201]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.555900 140167059183424 extract_features.py:201]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.556070 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.556281 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.556454 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.556655 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.556835 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.557009 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.557229 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.557412 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.557584 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.557788 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.557961 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.558135 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.558303 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.558476 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.558679 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.558853 140167059183424 extract_features.py:201]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.559020 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.559194 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.559361 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.559534 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.559754 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.559927 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.560128 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.560312 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.560482 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.560698 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.560867 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.561042 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.561258 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.561440 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.561649 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.561819 140167059183424 extract_features.py:201]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.561987 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.562161 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.562329 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.562530 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.562713 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.562888 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.563057 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.563230 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.563397 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.563597 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.563768 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.563942 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.564146 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.564321 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.564519 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.564693 140167059183424 extract_features.py:201]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.564865 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.565091 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.565262 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.565461 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.565641 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.565814 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.565982 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.566154 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.566320 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.566521 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.566691 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.566865 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.567032 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.567205 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.567410 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.567589 140167059183424 extract_features.py:201]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.567758 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.567958 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.568133 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.568308 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.568517 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.568693 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.568900 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.569084 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.569252 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.569491 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.569663 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.569867 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.570049 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.570223 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.570425 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.570595 140167059183424 extract_features.py:201]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.570762 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.570936 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.571102 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.571298 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.571478 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.571653 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.571820 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.571993 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.572197 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.572402 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.572573 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.572748 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.572963 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.573139 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.573355 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.573527 140167059183424 extract_features.py:201]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.573694 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.573907 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.574077 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.574283 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.574457 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.574631 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.574798 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.574971 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.575138 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.575357 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.575526 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.575726 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.575910 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.576086 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.576317 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.576487 140167059183424 extract_features.py:201]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.576655 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.576864 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.577034 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.577244 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.577416 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.577589 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.577808 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.577983 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.578205 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.578395 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.578562 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.578736 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.578903 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.579077 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.579280 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.579449 140167059183424 extract_features.py:201]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.579619 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.579828 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.579996 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.580204 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.580374 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.580547 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.580761 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.580935 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.581161 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.581335 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.581501 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.581675 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.581841 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.582036 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.582217 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.582386 140167059183424 extract_features.py:201]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.582554 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.582727 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.582894 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.583098 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.583273 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.583447 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.583650 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.583826 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.584017 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.584194 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.584362 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.584536 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.584748 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.584924 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.585145 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.585313 140167059183424 extract_features.py:201]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.585480 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.585653 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.585821 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.586064 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.586236 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.586410 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.586578 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.586750 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.586946 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.587123 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.587292 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.587466 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.587633 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.587805 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.588006 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.588176 140167059183424 extract_features.py:201]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.588343 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.588555 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.588724 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.588935 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.589108 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.589281 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.589499 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.589676 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.589875 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.590053 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.590222 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.590399 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.590566 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.590739 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.590943 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.591113 140167059183424 extract_features.py:201]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.591280 140167059183424 extract_features.py:201]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.591452 140167059183424 extract_features.py:201]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0816 16:24:25.592236 140167059183424 estimator.py:1147] Done calling model_fn.\n",
      "W0816 16:24:25.909810 140167059183424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "I0816 16:24:26.699123 140167059183424 monitored_session.py:240] Graph was finalized.\n",
      "2019-08-16 16:24:26.699562: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2019-08-16 16:24:26.713166: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2693765000 Hz\n",
      "2019-08-16 16:24:26.713597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x46f8300 executing computations on platform Host. Devices:\n",
      "2019-08-16 16:24:26.713655: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-08-16 16:24:27.585679: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "2019-08-16 16:24:28.046610: W tensorflow/core/framework/allocator.cc:107] Allocation of 98304000 exceeds 10% of system memory.\n",
      "I0816 16:24:30.700104 140167059183424 session_manager.py:500] Running local_init_op.\n",
      "I0816 16:24:30.804176 140167059183424 session_manager.py:502] Done running local_init_op.\n",
      "I0816 16:24:34.257504 140167059183424 error_handling.py:96] prediction_loop marked as finished\n",
      "I0816 16:24:34.257703 140167059183424 error_handling.py:96] prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 ../src/extract_features.py \\\n",
    "  --input_file=${INPUT_TEXTFILE_PATH} \\\n",
    "  --output_file=${OUTPUT_TEXTFILE_PATH} \\\n",
    "  --vocab_file=${TOKENIZER_MODEL_PATH}.vocab \\\n",
    "  --model_file=${TOKENIZER_MODEL_PATH}.model \\\n",
    "  --bert_config_file=${BERT_CONFIGFILE_PATH} \\\n",
    "  --init_checkpoint=${PRETRAINED_MODEL_PATH} \\\n",
    "  --layers=-1,-2,-3,-4 \\\n",
    "  --max_seq_length=${MAX_SEQ_LENGTH} \\\n",
    "  --batch_size=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■結果を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果ファイルを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "outputs = []\n",
    "with codecs.open(OUTPUT_TEXTFILE_PATH, 'r', 'utf-8') as fin:\n",
    "  for line in fin:\n",
    "    data = json.loads(line)\n",
    "    outputs.append(data)\n",
    "\n",
    "with codecs.open(OUTPUT_JSONFILE_PATH,'w', 'utf-8') as fout:\n",
    "  json.dump(outputs, fout, sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力文書の形態素解析結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文書 1 / 2\n",
      "  [CLS] ▁ すべての 人間 は 、 生 れ ながら にして 自由 であり 、 かつ 、 尊 厳 と 権利 と について 平等 である 。 \n",
      "  [SEP] ▁ 人間 は 、 理性 と 良 心 と を 授け られており 、 互いに 同胞 の精神 をもって 行動 しなければならない 。 \n",
      "  [SEP] \n",
      "\n",
      "文書 2 / 2\n",
      "  [CLS] ▁「 富士 〜」 で 有名な 動物園 は ? \n",
      "  [SEP] ▁「 富士 サ ファ リ パーク 」 です 。 \n",
      "  [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in outputs:\n",
    "  print('文書', (doc['linex_index'] + 1), '/', len(outputs))\n",
    "  print(' ', ' '.join([ feature['token'].replace('[SEP]', '\\n  [SEP]') for feature in doc['features'] ]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look at the features of the last layer for the word \"人間\".\n",
    "\n",
    "The 0-th token is always [CLS], and the 1st token of a sentence is [▁]. So the word comes in 3rd position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人間\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0]['features'][3]['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last layer is layer 0, the one before is layer -1, etc...\n",
    "The embeddings are stored in the *values* entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 「人間」の特徴ベクトルを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴ベクトルの次元数: 768 \n",
      "\n",
      "ノルム: 18.256403441334193 \n",
      "\n",
      "特徴ベクトル: [0.388213, -0.576151, -0.027084, -1.431741, 0.688938, -0.304473, 0.373505, -0.109832, -1.621072, -0.848877, -0.012777, 0.623844, -0.849169, -0.370514, -0.448757, 0.227168, -0.310765, 0.164168, -0.416387, -0.782097, 0.088901, 0.643659, 0.621601, 0.127453, 0.550596, -0.554063, 0.70033, -0.938487, 0.226078, -0.208362, 0.530374, -0.31495, 0.083271, -0.874866, 0.581575, -0.95967, 0.27626, 0.276187, 0.165083, -0.124819, -0.733634, 0.227352, 0.148887, 0.574101, -1.069794, -0.287446, 0.100649, -0.134502, 0.713487, -0.330703, 0.222692, -0.49073, -0.672788, 0.210758, -1.07941, -0.09508, 0.144539, 1.00762, 0.134064, 0.637895, -0.015204, -0.734581, 0.100435, -0.556787, -0.090496, -0.129595, -0.217037, 0.679371, 1.321034, 0.359275, 0.427882, -0.943426, -0.582211, -0.607388, -0.0033, 0.962177, 0.095276, -0.105843, 0.328633, 0.056413, -1.07188, 0.413312, 0.228835, -0.378046, 0.222511, -0.37087, 0.328615, 0.486272, 0.304307, 0.758792, -0.224085, 0.646336, -0.908637, -0.332553, -0.269778, -0.504732, 0.634655, -0.070552, -0.38159, -0.381884, -0.72248, 0.262959, 0.679435, -1.074854, -0.289017, 1.009495, -0.852392, -0.496721, 0.51598, -0.260099, 0.691492, -0.749672, -0.620987, -0.34462, -0.570107, -0.259039, -0.092656, -1.207708, -1.426698, 0.007026, 0.108178, -0.505355, -0.809476, -0.105395, -0.240364, 0.329558, 0.64504, -0.386434, -1.266391, 0.579092, -0.443622, 0.444698, -0.265557, 0.350072, -0.794397, 0.446988, -0.906472, 0.551562, 0.95631, -0.632905, 0.307319, 0.639494, 0.420389, 0.818026, 0.226604, -0.728806, -0.334631, 0.610887, -0.478483, 0.71872, -0.368436, 0.173347, -0.226575, 0.216486, -0.264799, 0.314514, -0.288768, 1.701368, -0.062295, -0.482494, 0.572278, -1.277753, -0.052438, 0.878044, -0.29234, -0.919011, 0.032979, 0.783157, -0.610471, -0.13852, 0.640983, 0.202299, 1.277717, 0.592836, -0.434784, -0.346737, 0.390598, 0.424341, 0.238603, -0.009215, 0.332812, 0.288226, 0.132748, -0.39771, 0.108909, -0.404773, -0.296352, -0.785482, 0.034951, -0.322201, 0.434836, -0.507801, -0.095517, 1.518494, -0.501066, 0.816092, -0.383939, -0.622844, 0.694035, -1.239756, 0.953153, -0.093215, -0.28657, -0.777773, 0.532145, -0.0821, 0.061485, -0.129373, -0.429815, 0.43906, 0.654834, 0.132249, 1.153229, 0.360217, 0.538194, -0.23022, -0.914715, 0.960521, -0.351385, -0.880074, -0.001583, 0.226397, -0.211603, 0.814155, -0.431537, 0.325968, -0.97851, -0.172099, 0.827928, 0.70175, 1.408917, 0.440613, 0.177432, -0.289084, 1.27409, 0.279033, 0.342406, -0.193579, -0.298053, 0.608288, 0.684961, 0.569005, 1.324312, -0.654412, 0.822549, 0.727947, 0.688686, 0.863985, -1.288407, -0.657574, -0.955242, -0.147465, -1.080628, -0.139777, -0.609754, -0.215484, -0.339843, -0.81907, 0.636771, 0.615081, 0.956695, 0.366734, -0.32017, -0.22863, -0.651548, -0.09283, -0.134934, 0.372956, -0.035162, 0.106434, -0.053785, -0.139865, 0.518166, 0.31207, 0.343539, -0.813013, 0.102421, 0.191973, 0.50493, -0.574628, 0.807271, 0.279218, 0.515471, 0.847236, -0.121986, 0.207419, 0.911739, 0.360685, 0.216118, -0.269342, -0.265746, -0.225853, 0.271322, -0.654961, -0.817007, -0.198647, 0.461257, 0.604366, 0.720325, 0.709559, 0.743386, -0.69136, 2.003338, 0.32535, -0.36788, -0.883858, -0.837398, 0.068534, -0.737504, -0.505384, 0.057593, 0.44208, 0.023007, -0.804935, 0.470689, -0.667472, 1.009733, -0.004834, -1.263496, 0.731636, -0.427596, 0.126545, 0.023592, 0.584873, -0.071452, 0.112195, -0.204154, -0.654316, -0.559676, 0.844863, -0.399569, -0.739437, 0.018947, -0.354754, 0.478669, -0.770717, -0.341854, -0.12737, -0.195107, -0.771011, 0.531207, -0.253594, -0.780964, 1.012232, -0.082164, 0.211602, -0.402288, -0.652301, 0.864497, -0.489236, 0.395584, 0.16066, 0.424714, 0.744904, 0.245094, -0.204593, -0.287583, -0.098262, -0.203543, -1.380861, 0.005909, 0.017359, 0.437497, -0.230665, 0.001963, 0.76597, -0.466717, -0.939774, -0.767767, -0.314794, -0.397696, 0.787126, -0.643548, 1.478166, -0.473703, -0.157553, -0.464315, -0.032047, -0.243721, 1.02014, -0.716222, -0.575478, -0.406135, 0.821519, 0.393943, -0.404728, -0.41764, 0.018557, 0.6581, 0.114365, 0.01092, 0.696797, -0.152719, 0.55302, 0.307923, -0.174024, -0.031344, -0.780428, -0.037488, 0.713319, -0.364195, 0.536659, -0.176224, -0.92218, -0.133392, 0.300916, 0.663137, -0.886282, -0.593731, 0.068932, 0.610387, -0.250612, -0.891541, -0.434216, 0.300521, 0.266207, 0.158772, 0.570461, -0.427768, 1.096945, 0.150431, -0.243281, -0.255428, 0.618958, 0.830503, 0.322451, 0.553074, -1.019231, 0.572131, 0.082766, -0.321719, -0.080961, -0.632444, 1.063981, 0.385604, 0.229008, 0.323201, -0.35512, 0.971159, 0.233976, -0.809056, 0.315257, 0.210047, -0.326582, 0.4453, -0.059352, -1.240805, -0.700779, -0.128645, -0.669642, -0.127687, 0.226745, 0.331688, 0.323053, 0.076743, 1.263401, 0.309658, 0.194175, 0.254088, 0.584643, -0.660163, 1.116992, 0.367865, -0.680852, -0.329849, -0.303349, 0.54306, 0.029249, 1.311194, 0.696272, 0.863068, 0.032816, 0.13584, 0.499276, 0.169985, -0.653865, -0.277286, 0.029186, -0.248308, 0.164426, -0.471202, 0.111102, 0.74318, 0.572385, -0.133692, -1.575346, 0.803057, 0.236616, 1.083916, -0.407451, -0.025249, 0.516676, 0.289989, 0.611959, -0.690677, -0.127929, -0.402055, -0.045343, -0.046431, 0.516828, 0.533223, 1.132915, -0.514707, -0.010772, -0.374923, 0.379337, -0.736562, -0.08419, -0.796652, -0.316486, 0.001146, 0.412879, 0.03199, 0.251292, 0.260822, 0.259173, -0.378638, 0.296995, -0.775764, 0.636961, 0.497434, -0.106331, -0.004283, 0.298794, -0.812736, -0.200299, -0.334777, -0.051539, -0.887895, -0.381166, 0.191391, 0.822583, -0.041136, 1.103585, -0.672544, 0.175134, -0.513704, -0.818248, -0.189217, -0.760943, -0.300632, 0.274014, -0.135261, -1.102422, -1.081753, -0.117498, 0.266441, -0.238506, -0.799631, -1.613833, 0.65398, -1.17141, 0.907887, 0.346957, 0.321792, -0.236054, -0.791907, 0.026393, 0.584947, 0.120672, -0.025805, 0.058214, -0.346303, 0.30368, -0.868398, -0.490077, 0.599238, -0.72812, -0.05632, 0.660286, -0.586863, -0.198811, -0.228955, 0.651223, 0.191175, -0.424265, 0.071612, 0.419971, -0.009771, 0.515192, -0.815368, 0.206046, 0.237397, 0.179159, -0.186832, -0.609882, -0.281853, -0.023763, 0.06417, 0.726532, 0.933694, -0.206425, -0.117049, 1.202951, 0.898542, -0.087145, 1.427161, -0.214832, 0.429623, 0.080241, -0.236868, -0.043955, 1.20367, -8.310433, -0.298806, 0.859119, -1.191795, -0.438189, -0.169005, 0.848166, 0.103648, -0.206269, -0.220293, -0.881038, -0.035977, 0.035143, 0.083323, 0.150634, -0.687285, -0.271688, -0.087415, 0.122835, 0.201918, -0.643922, -0.22392, -0.536704, -0.674115, -0.55502, 0.420135, 0.448638, -1.410998, 0.123407, 0.349638, 0.35071, 0.475618, 1.17579, 0.109792, 0.532526, -0.201122, 0.213708, -0.257216, -0.38629, 0.520239, -1.376476, -0.309901, 1.114371, 0.818738, -0.266359, 0.132414, 0.083885, -1.107013, -0.491873, -0.379632, 0.21407, -1.023597, -0.259933, 0.970023, -0.448365, -0.523207, 0.549213, -0.308318, 1.018309, -0.972982, -0.144808, 0.195913, 0.240318, -0.016181, 0.951909, -0.304788, -0.474214, 0.248121, -0.1233, 0.137547, 0.344751, -0.732934, -0.354988, -0.162847, 0.79407, -1.104247, -0.163215, -0.588597, 0.587884, -0.070843, -0.017523, -0.406672, 0.008266, 0.515761, 0.422139, -0.05518, -0.559294, -0.051661, 0.297413, 0.116431, 0.023215, -0.059211, 0.225285, 1.56327, 0.396323, 0.642608, 0.43422, 0.527197, -0.124444, -0.702694, 0.079606, 0.272614, -0.013955, -0.265239, 0.162669, 0.741345, -0.308716, 1.072018, -0.533768, 0.390182, 0.884414, -0.094913, 0.755754, -0.154432, -0.143708, -0.121287, 0.222329, -0.138382, -0.220302, -0.23907, 0.359176, 0.723228, 0.374856, 0.668778, 0.157449, -0.131602, 0.217612, -0.120795, 1.813959, -0.67509, 0.11863, -0.552904, -0.093726, -0.44282, 0.552447, 1.151681, 0.207133, 0.419347, 0.04557, -0.757443, 0.071706, 0.363509, 0.439924, -1.22993, 1.702249, 0.931312, 0.472788, 0.78273, -0.222013, -0.137623, -0.56852, -1.113385, -0.326022, -0.312265, -0.143017, -0.186031, 0.749005, -0.12254, 0.108111, -0.640673, -0.549286, -0.105754, -0.03891, 0.808191, -0.78411] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = outputs[0]['features'][3]['layers'][0]['values']\n",
    "\n",
    "print('特徴ベクトルの次元数:', len(embeddings), '\\n')\n",
    "print('ノルム:', np.linalg.norm(np.array(embeddings)), '\\n')\n",
    "print('特徴ベクトル:', embeddings, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
