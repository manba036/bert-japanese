{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴ベクトル抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■定数を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = '../config.ini'\n",
    "MAX_SEQ_LENGTH = 128\n",
    "PRETRAINED_MODEL_PATH = '../model/bert-wiki-ja/model.ckpt-1400000'\n",
    "TOKENIZER_MODEL_PATH = '../model/bert-wiki-ja/wiki-ja'\n",
    "INPUT_TEXTFILE_PATH = './data/input.txt'\n",
    "OUTPUT_TEXTFILE_PATH = './data/output.txt'\n",
    "OUTPUT_JSONFILE_PATH = './data/output.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■モジュールを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manba/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/manba/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import tarfile \n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import tempfile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src\")\n",
    "from utils import str_to_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../bert\")\n",
    "import modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■設定ファイルを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config.ini']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEURL = config['FINETUNING-DATA']['FILEURL']\n",
    "FILEPATH = config['FINETUNING-DATA']['FILEPATH']\n",
    "EXTRACTDIR = config['FINETUNING-DATA']['TEXTDIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.json')\n",
    "bert_config_file.write(json.dumps({k:str_to_value(v) for k,v in config['BERT-CONFIG'].items()}))\n",
    "bert_config_file.seek(0)\n",
    "bert_config_file_path = str(bert_config_file.name)\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■入力文書を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo 'すべての人間は、生れながらにして自由であり、かつ、尊厳と権利とについて平等である。 ||| 人間は、理性と良心とを授けられており、互いに同胞の精神をもって行動しなければならない。' > {INPUT_TEXTFILE_PATH}\n",
    "!echo '「富士〜」で有名な動物園は？ ||| 「富士サファリパーク」です。' >> {INPUT_TEXTFILE_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■特徴ベクトルを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 01:04:49.431474 140567494973248 deprecation_wrapper.py:119] From ../src/extract_features.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "Loaded a trained SentencePiece model.\n",
      "W0813 01:04:49.715533 140567494973248 deprecation_wrapper.py:119] From /home/manba/work/bert-japanese/src/tokenization_sentencepiece.py:115: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0813 01:04:53.977297 140567494973248 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0813 01:04:53.982577 140567494973248 deprecation_wrapper.py:119] From ../src/extract_features.py:292: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0813 01:04:53.983580 140567494973248 extract_features.py:292] *** Example ***\n",
      "I0813 01:04:53.984045 140567494973248 extract_features.py:293] unique_id: 0\n",
      "I0813 01:04:53.984666 140567494973248 extract_features.py:295] tokens: [CLS] ▁ すべての 人間 は 、 生 れ ながら にして 自由 であり 、 かつ 、 尊 厳 と 権利 と について 平等 である 。 [SEP] ▁ 人間 は 、 理性 と 良 心 と を 授け られており 、 互いに 同胞 の精神 をもって 行動 しなければならない 。 [SEP]\n",
      "I0813 01:04:53.985527 140567494973248 extract_features.py:296] input_ids: 4 9 2145 858 11 7 196 964 527 2113 1325 75 7 1368 7 3201 3586 20 3334 20 257 10838 27 8 5 9 858 11 7 18570 20 856 509 20 18 15611 8880 7 6109 27717 14647 1806 1216 6807 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0813 01:04:53.986537 140567494973248 extract_features.py:297] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0813 01:04:53.987166 140567494973248 extract_features.py:299] input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0813 01:04:53.989675 140567494973248 extract_features.py:292] *** Example ***\n",
      "I0813 01:04:53.990911 140567494973248 extract_features.py:293] unique_id: 1\n",
      "I0813 01:04:53.992878 140567494973248 extract_features.py:295] tokens: [CLS] ▁「 富士 〜」 で 有名な 動物園 は ? [SEP] ▁「 富士 サ ファ リ パーク 」 です 。 [SEP]\n",
      "I0813 01:04:53.993841 140567494973248 extract_features.py:296] input_ids: 4 235 2915 10341 19 3225 12507 11 3017 5 235 2915 209 726 146 2361 21 2767 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0813 01:04:53.994668 140567494973248 extract_features.py:297] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I0813 01:04:53.995644 140567494973248 extract_features.py:299] input_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "W0813 01:04:53.998613 140567494973248 estimator.py:1984] Estimator's model_fn (<function model_fn at 0x7fd834d2e758>) includes params argument, but params are not passed to Estimator.\n",
      "W0813 01:04:54.006102 140567494973248 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpECQG79\n",
      "I0813 01:04:54.011157 140567494973248 estimator.py:209] Using config: {'_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd834d4b150>, '_model_dir': '/tmp/tmpECQG79', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_cluster': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}\n",
      "I0813 01:04:54.013010 140567494973248 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
      "W0813 01:04:54.016396 140567494973248 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
      "W0813 01:04:54.017884 140567494973248 deprecation_wrapper.py:119] From ../src/extract_features.py:407: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "I0813 01:04:54.019778 140567494973248 estimator.py:612] Could not find trained model in model_dir: /tmp/tmpECQG79, running initialization to predict.\n",
      "I0813 01:04:54.153004 140567494973248 estimator.py:1145] Calling model_fn.\n",
      "I0813 01:04:54.154077 140567494973248 tpu_estimator.py:2965] Running infer on CPU\n",
      "W0813 01:04:54.176059 140567494973248 deprecation_wrapper.py:119] From ../bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0813 01:04:54.186547 140567494973248 deprecation_wrapper.py:119] From ../bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0813 01:04:54.323036 140567494973248 deprecation_wrapper.py:119] From ../bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W0813 01:04:54.753014 140567494973248 deprecation.py:323] From ../bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0813 01:05:02.945095 140567494973248 deprecation_wrapper.py:119] From ../src/extract_features.py:180: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0813 01:05:02.960752 140567494973248 deprecation_wrapper.py:119] From ../src/extract_features.py:193: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "I0813 01:05:05.281852 140567494973248 extract_features.py:195] **** Trainable Variables ****\n",
      "I0813 01:05:05.282269 140567494973248 extract_features.py:201]   name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.282685 140567494973248 extract_features.py:201]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.282998 140567494973248 extract_features.py:201]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.283332 140567494973248 extract_features.py:201]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.283718 140567494973248 extract_features.py:201]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.284039 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.284599 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.284877 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.285305 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.285728 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.286087 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.286391 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.286895 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.287296 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.287599 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.287899 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.288161 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.288505 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.289139 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.289524 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.289787 140567494973248 extract_features.py:201]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.290047 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.290523 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.291475 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.291928 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.292431 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.292778 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.293087 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.293489 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.293935 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.294348 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.294770 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.295370 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.295799 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.296343 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.296701 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.297318 140567494973248 extract_features.py:201]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.297791 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.298243 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.298748 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.299098 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.299529 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.299875 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.300302 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.300654 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.301057 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.301410 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.301676 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.302015 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.302536 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.303087 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.303472 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.303874 140567494973248 extract_features.py:201]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.304311 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.304663 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.304956 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.305267 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.305516 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.305824 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.306288 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.306632 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.307020 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.307441 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.307730 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.308197 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.308780 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.309240 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.309654 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.310014 140567494973248 extract_features.py:201]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.310340 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.310684 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.311062 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.311417 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.311745 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.312205 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.312551 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.312937 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.313266 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.313597 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.313966 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.314300 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.314614 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.315028 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.315349 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.315659 140567494973248 extract_features.py:201]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.315998 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.316236 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.316457 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.316766 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.316996 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.317230 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.317496 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.317734 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.317971 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.318193 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.318443 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.318746 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.318977 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.319214 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.319461 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.319789 140567494973248 extract_features.py:201]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.320097 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.320410 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.320768 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.321067 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.321345 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.321628 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.321921 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.322151 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.322365 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.322621 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.322845 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.323074 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.323333 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.323601 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.323824 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.324043 140567494973248 extract_features.py:201]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.324258 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.324503 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.324801 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.325257 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.325525 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.325762 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.325987 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.326215 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.326426 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.326687 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.326909 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.327141 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.327353 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.327616 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.327833 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.328097 140567494973248 extract_features.py:201]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.328316 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.328630 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.328859 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.329085 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.329298 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.329560 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.329777 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.330003 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.330219 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.330496 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.330764 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.330992 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.331206 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.331476 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.331695 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.331939 140567494973248 extract_features.py:201]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.332145 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.332400 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.332611 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.332829 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.333051 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.333301 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.333614 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.333844 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.334060 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.334311 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.334538 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.334762 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.335000 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.335252 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.335489 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.335704 140567494973248 extract_features.py:201]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.335985 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.336244 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.336505 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.336733 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.336946 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.337161 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.337414 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.337629 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.337836 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.338048 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.338344 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.338566 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.338781 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.338994 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.339234 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.339446 140567494973248 extract_features.py:201]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.339658 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.339874 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.340080 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.340390 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.340603 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.340823 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.341031 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.341296 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.341624 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.341835 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.342071 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.342365 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.342672 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.342895 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.343136 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.343348 140567494973248 extract_features.py:201]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.343565 140567494973248 extract_features.py:201]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.343792 140567494973248 extract_features.py:201]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I0813 01:05:05.345124 140567494973248 estimator.py:1147] Done calling model_fn.\n",
      "W0813 01:05:05.994771 140567494973248 deprecation.py:323] From /home/manba/.local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py:1354: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "I0813 01:05:07.388149 140567494973248 monitored_session.py:240] Graph was finalized.\n",
      "2019-08-13 01:05:07.390677: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2019-08-13 01:05:07.418031: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2693770000 Hz\n",
      "2019-08-13 01:05:07.418692: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563ed980cbc0 executing computations on platform Host. Devices:\n",
      "2019-08-13 01:05:07.418830: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-08-13 01:05:10.026018: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0813 01:05:13.897262 140567494973248 session_manager.py:500] Running local_init_op.\n",
      "I0813 01:05:14.238537 140567494973248 session_manager.py:502] Done running local_init_op.\n",
      "I0813 01:05:22.632749 140567494973248 error_handling.py:96] prediction_loop marked as finished\n",
      "I0813 01:05:22.633621 140567494973248 error_handling.py:96] prediction_loop marked as finished\n"
     ]
    }
   ],
   "source": [
    "!python ../src/extract_features.py \\\n",
    "  --input_file={INPUT_TEXTFILE_PATH} \\\n",
    "  --output_file={OUTPUT_TEXTFILE_PATH} \\\n",
    "  --vocab_file={TOKENIZER_MODEL_PATH}.vocab \\\n",
    "  --model_file={TOKENIZER_MODEL_PATH}.model \\\n",
    "  --bert_config_file={bert_config_file.name} \\\n",
    "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
    "  --layers=-1,-2,-3,-4 \\\n",
    "  --max_seq_length={MAX_SEQ_LENGTH} \\\n",
    "  --batch_size=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■結果を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果ファイルを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "outputs = []\n",
    "with codecs.open(OUTPUT_TEXTFILE_PATH, 'r', 'utf-8') as fin:\n",
    "  for line in fin:\n",
    "    data = json.loads(line)\n",
    "    outputs.append(data)\n",
    "\n",
    "with codecs.open(OUTPUT_JSONFILE_PATH,'w', 'utf-8') as fout:\n",
    "  json.dump(outputs, fout, sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力文書の形態素解析結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文書 1 / 2\n",
      "  [CLS] ▁ すべての 人間 は 、 生 れ ながら にして 自由 であり 、 かつ 、 尊 厳 と 権利 と について 平等 である 。 \n",
      "  [SEP] ▁ 人間 は 、 理性 と 良 心 と を 授け られており 、 互いに 同胞 の精神 をもって 行動 しなければならない 。 \n",
      "  [SEP] \n",
      "\n",
      "文書 2 / 2\n",
      "  [CLS] ▁「 富士 〜」 で 有名な 動物園 は ? \n",
      "  [SEP] ▁「 富士 サ ファ リ パーク 」 です 。 \n",
      "  [SEP] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc in outputs:\n",
    "  print('文書', (doc['linex_index'] + 1), '/', len(outputs))\n",
    "  print(' ', ' '.join([ feature['token'].replace('[SEP]', '\\n  [SEP]') for feature in doc['features'] ]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look at the features of the last layer for the word \"人間\".\n",
    "\n",
    "The 0-th token is always [CLS], and the 1st token of a sentence is [▁]. So the word comes in 3rd position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人間\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0]['features'][3]['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last layer is layer 0, the one before is layer -1, etc...\n",
    "The embeddings are stored in the *values* entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 「人間」の特徴ベクトルを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴ベクトルの次元数: 768 \n",
      "\n",
      "ノルム: 18.256403441334193 \n",
      "\n",
      "特徴ベクトル: [0.388213, -0.576151, -0.027084, -1.431741, 0.688938, -0.304473, 0.373505, -0.109832, -1.621072, -0.848877, -0.012777, 0.623844, -0.849169, -0.370514, -0.448757, 0.227168, -0.310765, 0.164168, -0.416387, -0.782097, 0.088901, 0.643659, 0.621601, 0.127453, 0.550596, -0.554063, 0.70033, -0.938487, 0.226078, -0.208362, 0.530374, -0.31495, 0.083271, -0.874866, 0.581575, -0.95967, 0.27626, 0.276187, 0.165083, -0.124819, -0.733634, 0.227352, 0.148887, 0.574101, -1.069794, -0.287446, 0.100649, -0.134502, 0.713487, -0.330703, 0.222692, -0.49073, -0.672788, 0.210758, -1.07941, -0.09508, 0.144539, 1.00762, 0.134064, 0.637895, -0.015204, -0.734581, 0.100435, -0.556787, -0.090496, -0.129595, -0.217037, 0.679371, 1.321034, 0.359275, 0.427882, -0.943426, -0.582211, -0.607388, -0.0033, 0.962177, 0.095276, -0.105843, 0.328633, 0.056413, -1.07188, 0.413312, 0.228835, -0.378046, 0.222511, -0.37087, 0.328615, 0.486272, 0.304307, 0.758792, -0.224085, 0.646336, -0.908637, -0.332553, -0.269778, -0.504732, 0.634655, -0.070552, -0.38159, -0.381884, -0.72248, 0.262959, 0.679435, -1.074854, -0.289017, 1.009495, -0.852392, -0.496721, 0.51598, -0.260099, 0.691492, -0.749672, -0.620987, -0.34462, -0.570107, -0.259039, -0.092656, -1.207708, -1.426698, 0.007026, 0.108178, -0.505355, -0.809476, -0.105395, -0.240364, 0.329558, 0.64504, -0.386434, -1.266391, 0.579092, -0.443622, 0.444698, -0.265557, 0.350072, -0.794397, 0.446988, -0.906472, 0.551562, 0.95631, -0.632905, 0.307319, 0.639494, 0.420389, 0.818026, 0.226604, -0.728806, -0.334631, 0.610887, -0.478483, 0.71872, -0.368436, 0.173347, -0.226575, 0.216486, -0.264799, 0.314514, -0.288768, 1.701368, -0.062295, -0.482494, 0.572278, -1.277753, -0.052438, 0.878044, -0.29234, -0.919011, 0.032979, 0.783157, -0.610471, -0.13852, 0.640983, 0.202299, 1.277717, 0.592836, -0.434784, -0.346737, 0.390598, 0.424341, 0.238603, -0.009215, 0.332812, 0.288226, 0.132748, -0.39771, 0.108909, -0.404773, -0.296352, -0.785482, 0.034951, -0.322201, 0.434836, -0.507801, -0.095517, 1.518494, -0.501066, 0.816092, -0.383939, -0.622844, 0.694035, -1.239756, 0.953153, -0.093215, -0.28657, -0.777773, 0.532145, -0.0821, 0.061485, -0.129373, -0.429815, 0.43906, 0.654834, 0.132249, 1.153229, 0.360217, 0.538194, -0.23022, -0.914715, 0.960521, -0.351385, -0.880074, -0.001583, 0.226397, -0.211603, 0.814155, -0.431537, 0.325968, -0.97851, -0.172099, 0.827928, 0.70175, 1.408917, 0.440613, 0.177432, -0.289084, 1.27409, 0.279033, 0.342406, -0.193579, -0.298053, 0.608288, 0.684961, 0.569005, 1.324312, -0.654412, 0.822549, 0.727947, 0.688686, 0.863985, -1.288407, -0.657574, -0.955242, -0.147465, -1.080628, -0.139777, -0.609754, -0.215484, -0.339843, -0.81907, 0.636771, 0.615081, 0.956695, 0.366734, -0.32017, -0.22863, -0.651548, -0.09283, -0.134934, 0.372956, -0.035162, 0.106434, -0.053785, -0.139865, 0.518166, 0.31207, 0.343539, -0.813013, 0.102421, 0.191973, 0.50493, -0.574628, 0.807271, 0.279218, 0.515471, 0.847236, -0.121986, 0.207419, 0.911739, 0.360685, 0.216118, -0.269342, -0.265746, -0.225853, 0.271322, -0.654961, -0.817007, -0.198647, 0.461257, 0.604366, 0.720325, 0.709559, 0.743386, -0.69136, 2.003338, 0.32535, -0.36788, -0.883858, -0.837398, 0.068534, -0.737504, -0.505384, 0.057593, 0.44208, 0.023007, -0.804935, 0.470689, -0.667472, 1.009733, -0.004834, -1.263496, 0.731636, -0.427596, 0.126545, 0.023592, 0.584873, -0.071452, 0.112195, -0.204154, -0.654316, -0.559676, 0.844863, -0.399569, -0.739437, 0.018947, -0.354754, 0.478669, -0.770717, -0.341854, -0.12737, -0.195107, -0.771011, 0.531207, -0.253594, -0.780964, 1.012232, -0.082164, 0.211602, -0.402288, -0.652301, 0.864497, -0.489236, 0.395584, 0.16066, 0.424714, 0.744904, 0.245094, -0.204593, -0.287583, -0.098262, -0.203543, -1.380861, 0.005909, 0.017359, 0.437497, -0.230665, 0.001963, 0.76597, -0.466717, -0.939774, -0.767767, -0.314794, -0.397696, 0.787126, -0.643548, 1.478166, -0.473703, -0.157553, -0.464315, -0.032047, -0.243721, 1.02014, -0.716222, -0.575478, -0.406135, 0.821519, 0.393943, -0.404728, -0.41764, 0.018557, 0.6581, 0.114365, 0.01092, 0.696797, -0.152719, 0.55302, 0.307923, -0.174024, -0.031344, -0.780428, -0.037488, 0.713319, -0.364195, 0.536659, -0.176224, -0.92218, -0.133392, 0.300916, 0.663137, -0.886282, -0.593731, 0.068932, 0.610387, -0.250612, -0.891541, -0.434216, 0.300521, 0.266207, 0.158772, 0.570461, -0.427768, 1.096945, 0.150431, -0.243281, -0.255428, 0.618958, 0.830503, 0.322451, 0.553074, -1.019231, 0.572131, 0.082766, -0.321719, -0.080961, -0.632444, 1.063981, 0.385604, 0.229008, 0.323201, -0.35512, 0.971159, 0.233976, -0.809056, 0.315257, 0.210047, -0.326582, 0.4453, -0.059352, -1.240805, -0.700779, -0.128645, -0.669642, -0.127687, 0.226745, 0.331688, 0.323053, 0.076743, 1.263401, 0.309658, 0.194175, 0.254088, 0.584643, -0.660163, 1.116992, 0.367865, -0.680852, -0.329849, -0.303349, 0.54306, 0.029249, 1.311194, 0.696272, 0.863068, 0.032816, 0.13584, 0.499276, 0.169985, -0.653865, -0.277286, 0.029186, -0.248308, 0.164426, -0.471202, 0.111102, 0.74318, 0.572385, -0.133692, -1.575346, 0.803057, 0.236616, 1.083916, -0.407451, -0.025249, 0.516676, 0.289989, 0.611959, -0.690677, -0.127929, -0.402055, -0.045343, -0.046431, 0.516828, 0.533223, 1.132915, -0.514707, -0.010772, -0.374923, 0.379337, -0.736562, -0.08419, -0.796652, -0.316486, 0.001146, 0.412879, 0.03199, 0.251292, 0.260822, 0.259173, -0.378638, 0.296995, -0.775764, 0.636961, 0.497434, -0.106331, -0.004283, 0.298794, -0.812736, -0.200299, -0.334777, -0.051539, -0.887895, -0.381166, 0.191391, 0.822583, -0.041136, 1.103585, -0.672544, 0.175134, -0.513704, -0.818248, -0.189217, -0.760943, -0.300632, 0.274014, -0.135261, -1.102422, -1.081753, -0.117498, 0.266441, -0.238506, -0.799631, -1.613833, 0.65398, -1.17141, 0.907887, 0.346957, 0.321792, -0.236054, -0.791907, 0.026393, 0.584947, 0.120672, -0.025805, 0.058214, -0.346303, 0.30368, -0.868398, -0.490077, 0.599238, -0.72812, -0.05632, 0.660286, -0.586863, -0.198811, -0.228955, 0.651223, 0.191175, -0.424265, 0.071612, 0.419971, -0.009771, 0.515192, -0.815368, 0.206046, 0.237397, 0.179159, -0.186832, -0.609882, -0.281853, -0.023763, 0.06417, 0.726532, 0.933694, -0.206425, -0.117049, 1.202951, 0.898542, -0.087145, 1.427161, -0.214832, 0.429623, 0.080241, -0.236868, -0.043955, 1.20367, -8.310433, -0.298806, 0.859119, -1.191795, -0.438189, -0.169005, 0.848166, 0.103648, -0.206269, -0.220293, -0.881038, -0.035977, 0.035143, 0.083323, 0.150634, -0.687285, -0.271688, -0.087415, 0.122835, 0.201918, -0.643922, -0.22392, -0.536704, -0.674115, -0.55502, 0.420135, 0.448638, -1.410998, 0.123407, 0.349638, 0.35071, 0.475618, 1.17579, 0.109792, 0.532526, -0.201122, 0.213708, -0.257216, -0.38629, 0.520239, -1.376476, -0.309901, 1.114371, 0.818738, -0.266359, 0.132414, 0.083885, -1.107013, -0.491873, -0.379632, 0.21407, -1.023597, -0.259933, 0.970023, -0.448365, -0.523207, 0.549213, -0.308318, 1.018309, -0.972982, -0.144808, 0.195913, 0.240318, -0.016181, 0.951909, -0.304788, -0.474214, 0.248121, -0.1233, 0.137547, 0.344751, -0.732934, -0.354988, -0.162847, 0.79407, -1.104247, -0.163215, -0.588597, 0.587884, -0.070843, -0.017523, -0.406672, 0.008266, 0.515761, 0.422139, -0.05518, -0.559294, -0.051661, 0.297413, 0.116431, 0.023215, -0.059211, 0.225285, 1.56327, 0.396323, 0.642608, 0.43422, 0.527197, -0.124444, -0.702694, 0.079606, 0.272614, -0.013955, -0.265239, 0.162669, 0.741345, -0.308716, 1.072018, -0.533768, 0.390182, 0.884414, -0.094913, 0.755754, -0.154432, -0.143708, -0.121287, 0.222329, -0.138382, -0.220302, -0.23907, 0.359176, 0.723228, 0.374856, 0.668778, 0.157449, -0.131602, 0.217612, -0.120795, 1.813959, -0.67509, 0.11863, -0.552904, -0.093726, -0.44282, 0.552447, 1.151681, 0.207133, 0.419347, 0.04557, -0.757443, 0.071706, 0.363509, 0.439924, -1.22993, 1.702249, 0.931312, 0.472788, 0.78273, -0.222013, -0.137623, -0.56852, -1.113385, -0.326022, -0.312265, -0.143017, -0.186031, 0.749005, -0.12254, 0.108111, -0.640673, -0.549286, -0.105754, -0.03891, 0.808191, -0.78411] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = outputs[0]['features'][3]['layers'][0]['values']\n",
    "\n",
    "print('特徴ベクトルの次元数:', len(embeddings), '\\n')\n",
    "print('ノルム:', np.linalg.norm(np.array(embeddings)), '\\n')\n",
    "print('特徴ベクトル:', embeddings, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
